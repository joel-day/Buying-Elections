{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9d5e27",
      "metadata": {
        "id": "fd9d5e27"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "year = 2020\n",
        "yeara = str(year)\n",
        "year2 = year - 1\n",
        "yearb = str(year2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6965fa",
      "metadata": {
        "id": "1d6965fa"
      },
      "source": [
        "## https://www.fec.gov/data/browse-data/?tab=bulk-data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df09d00",
      "metadata": {
        "id": "0df09d00"
      },
      "source": [
        "## Load contribution Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ad07a9",
      "metadata": {
        "id": "26ad07a9",
        "outputId": "1b19726d-a338-4655-cc3d-4aeeb8f0c835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [CMTE_ID, AMNDT_IND, RPT_TP, TRANSACTION_PGI, IMAGE_NUM, TRANSACTION_TP, ENTITY_TP, NAME, CITY, STATE, ZIP_CODE, EMPLOYER, OCCUPATION, TRANSACTION_DT, TRANSACTION_AMT, OTHER_ID, TRAN_ID, FILE_NUM, MEMO_CD, MEMO_TEXT, SUB_ID]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 21 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_9744\\466088873.py:13: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df1 = pd.read_csv('20.txt', sep='|', engine='python', error_bad_lines=False)\n",
            "Skipping line 319331: '|' expected after '\"'\n",
            "Skipping line 1986154: '|' expected after '\"'\n",
            "Skipping line 3438882: '|' expected after '\"'\n",
            "Skipping line 3544071: '|' expected after '\"'\n",
            "Skipping line 3651830: '|' expected after '\"'\n",
            "Skipping line 6539806: '|' expected after '\"'\n",
            "Skipping line 6548428: '|' expected after '\"'\n",
            "Skipping line 7472313: field larger than field limit (131072)\n",
            "Skipping line 7563227: field larger than field limit (131072)\n",
            "Skipping line 7564267: field larger than field limit (131072)\n",
            "Skipping line 7762689: '|' expected after '\"'\n",
            "Skipping line 9441472: '|' expected after '\"'\n",
            "Skipping line 9898873: '|' expected after '\"'\n",
            "Skipping line 9953625: '|' expected after '\"'\n",
            "Skipping line 10056787: '|' expected after '\"'\n",
            "Skipping line 10103511: '|' expected after '\"'\n",
            "Skipping line 10707066: '|' expected after '\"'\n",
            "Skipping line 14128010: '|' expected after '\"'\n",
            "Skipping line 15120248: '|' expected after '\"'\n",
            "Skipping line 15358855: '|' expected after '\"'\n",
            "Skipping line 15467818: '|' expected after '\"'\n",
            "Skipping line 16067161: '|' expected after '\"'\n",
            "Skipping line 16304128: '|' expected after '\"'\n",
            "Skipping line 16971341: '|' expected after '\"'\n",
            "Skipping line 18080532: '|' expected after '\"'\n",
            "Skipping line 20601650: '|' expected after '\"'\n",
            "Skipping line 21193986: '|' expected after '\"'\n",
            "Skipping line 21667748: '|' expected after '\"'\n",
            "Skipping line 21737688: field larger than field limit (131072)\n",
            "Skipping line 21963127: '|' expected after '\"'\n",
            "Skipping line 23405412: '|' expected after '\"'\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Read the header file into a DataFrame\n",
        "df = pd.read_csv('indiv_header_file.csv')\n",
        "\n",
        "# Step 3: Inspect the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Step 4: Save the DataFrame to a file\n",
        "column_names = df.columns.tolist()\n",
        "\n",
        "#df1 = pd.read_csv('20.txt', sep='|', names=column_names)\n",
        "\n",
        "try:\n",
        "    df1 = pd.read_csv('16.txt', sep='|', engine='python', error_bad_lines=False)\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f4f8b5",
      "metadata": {
        "id": "98f4f8b5"
      },
      "outputs": [],
      "source": [
        "df1.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ad2dc6",
      "metadata": {
        "id": "c6ad2dc6"
      },
      "source": [
        "## Filter out irrelevant contribution data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "be8af847",
      "metadata": {
        "id": "be8af847"
      },
      "outputs": [],
      "source": [
        "can_ids = pd.read_excel('filtered_project_committees.xlsx')\n",
        "can_ids_list = can_ids['committee_id'].to_list()\n",
        "len(can_ids_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "01ffc477",
      "metadata": {
        "id": "01ffc477"
      },
      "outputs": [],
      "source": [
        "filtered_df1 = df1[df1['CMTE_ID'].isin(can_ids_list)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f06b0a",
      "metadata": {
        "id": "e5f06b0a"
      },
      "source": [
        "## Drop irrelevant columns and format date columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d0d956",
      "metadata": {
        "id": "51d0d956"
      },
      "outputs": [],
      "source": [
        "selected_columns = filtered_df1[['CMTE_ID', 'TRANSACTION_DT', 'TRANSACTION_AMT']]\n",
        "selected_columns['TRANSACTION_DT'] = selected_columns['TRANSACTION_DT'].astype(str)\n",
        "\n",
        "# remove rows with out properly formated dates\n",
        "selected_columns = selected_columns[selected_columns['TRANSACTION_DT'].apply(len).isin([9, 10])]\n",
        "\n",
        "# formate date column\n",
        "selected_columns['Year'] = selected_columns['TRANSACTION_DT'].str[-6:-2]\n",
        "selected_columns['Date'] = selected_columns['TRANSACTION_DT'].str[-8:-6]\n",
        "selected_columns['Month'] = selected_columns['TRANSACTION_DT'].str[:-8]\n",
        "\n",
        "# remove rows that arnt within two years of the election\n",
        "selected_columns = selected_columns[selected_columns['Year'].str.startswith((yeara, yearb))]\n",
        "selected_columns.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f4120c",
      "metadata": {
        "id": "78f4120c"
      },
      "source": [
        "## Verify Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5549da",
      "metadata": {
        "id": "8b5549da"
      },
      "outputs": [],
      "source": [
        "unique_combos = selected_columns[['Month', 'Year']]\n",
        "\n",
        "# Group by 'Month' and 'Year', then get the counts\n",
        "combo_counts = unique_combos.groupby(['Month', 'Year']).size().reset_index(name='Count')\n",
        "combo_counts = combo_counts.apply(pd.to_numeric)\n",
        "combo_counts = combo_counts.sort_values(by=['Year', 'Month'])\n",
        "print(combo_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f92f1d",
      "metadata": {
        "id": "84f92f1d"
      },
      "source": [
        "## Create and download an excel file for each month of contributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bcf3c88",
      "metadata": {
        "id": "5bcf3c88"
      },
      "outputs": [],
      "source": [
        "# create 'months' folder if it doesn't exist\n",
        "if not os.path.exists('months'):\n",
        "    os.makedirs('months')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e092938f",
      "metadata": {
        "id": "e092938f"
      },
      "outputs": [],
      "source": [
        "# list of all months\n",
        "unique_year_month_combos = selected_columns[['Year', 'Month']].drop_duplicates()\n",
        "year_month_list = [(row['Year'], row['Month']) for _, row in unique_year_month_combos.iterrows()]\n",
        "\n",
        "# iterate over each month\n",
        "for year, month in year_month_list:\n",
        "\n",
        "    filtered_df = selected_columns[(selected_columns['Year'] == year) & (selected_columns['Month'] == month)]\n",
        "\n",
        "    # save to the folder\n",
        "    file_path = os.path.join('months/', f'{year}_{month}.csv')\n",
        "    filtered_df.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"Data frames have been saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc0558f",
      "metadata": {
        "id": "1bc0558f"
      },
      "source": [
        "# 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c4fb09",
      "metadata": {
        "id": "22c4fb09"
      },
      "source": [
        "## Above worked for 16 and 18 but the file size for 2020 was too big so i had to use a program called H-J split to break it down into 14 smaller files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d6f112",
      "metadata": {
        "id": "d4d6f112"
      },
      "source": [
        "## of the 14 files 3 of them did not have '.0' at the end of the date. so i had to adust the code to make it work for them. (4 &10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18356632",
      "metadata": {
        "id": "18356632",
        "outputId": "517e2253-6327-4d99-b636-3d8ca45879b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [CMTE_ID, AMNDT_IND, RPT_TP, TRANSACTION_PGI, IMAGE_NUM, TRANSACTION_TP, ENTITY_TP, NAME, CITY, STATE, ZIP_CODE, EMPLOYER, OCCUPATION, TRANSACTION_DT, TRANSACTION_AMT, OTHER_ID, TRAN_ID, FILE_NUM, MEMO_CD, MEMO_TEXT, SUB_ID]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "number = '008'\n",
        "\n",
        "import pandas as pd\n",
        "# Step 2: Read the header file into a DataFrame\n",
        "df = pd.read_csv('indiv_header_file.csv')\n",
        "\n",
        "# Step 3: Inspect the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Step 4: Save the DataFrame to a file\n",
        "column_names = df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67ca711",
      "metadata": {
        "scrolled": true,
        "id": "c67ca711",
        "outputId": "3a2b7b30-b66d-430b-ccef-2ce1473f366e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_14680\\2104414943.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df1 = pd.read_csv(f'chunks/20.txt.{number}.txt', sep='|', engine='python', names=column_names, error_bad_lines=False)\n"
          ]
        }
      ],
      "source": [
        "#df1 = pd.read_csv('20.txt', sep='|', names=column_names)\n",
        "df1 = pd.read_csv(f'chunks/20.txt.{number}.txt', sep='|', engine='python', names=column_names, error_bad_lines=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fed899",
      "metadata": {
        "id": "82fed899",
        "outputId": "225ca03a-b442-415b-9a92-f5832813e8d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CMTE_ID</th>\n",
              "      <th>AMNDT_IND</th>\n",
              "      <th>RPT_TP</th>\n",
              "      <th>TRANSACTION_PGI</th>\n",
              "      <th>IMAGE_NUM</th>\n",
              "      <th>TRANSACTION_TP</th>\n",
              "      <th>ENTITY_TP</th>\n",
              "      <th>NAME</th>\n",
              "      <th>CITY</th>\n",
              "      <th>STATE</th>\n",
              "      <th>...</th>\n",
              "      <th>EMPLOYER</th>\n",
              "      <th>OCCUPATION</th>\n",
              "      <th>TRANSACTION_DT</th>\n",
              "      <th>TRANSACTION_AMT</th>\n",
              "      <th>OTHER_ID</th>\n",
              "      <th>TRAN_ID</th>\n",
              "      <th>FILE_NUM</th>\n",
              "      <th>MEMO_CD</th>\n",
              "      <th>MEMO_TEXT</th>\n",
              "      <th>SUB_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GINEER</td>\n",
              "      <td>05232019</td>\n",
              "      <td>250</td>\n",
              "      <td>C00401224</td>\n",
              "      <td>857500</td>\n",
              "      <td>1369136</td>\n",
              "      <td>NaN</td>\n",
              "      <td>* EARMARKED CONTRIBUTION: SEE BELOW</td>\n",
              "      <td>4011320201684008049</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C00697441</td>\n",
              "      <td>A</td>\n",
              "      <td>Q2</td>\n",
              "      <td>P2020</td>\n",
              "      <td>202001089167037289</td>\n",
              "      <td>15E</td>\n",
              "      <td>IND</td>\n",
              "      <td>FREEMON, PHILLIP</td>\n",
              "      <td>SAN FRANCISCO</td>\n",
              "      <td>CA</td>\n",
              "      <td>...</td>\n",
              "      <td>SELF-EMPLOYED</td>\n",
              "      <td>ATTORNEY</td>\n",
              "      <td>4162019.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>C00401224</td>\n",
              "      <td>747383</td>\n",
              "      <td>1369136.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>* EARMARKED CONTRIBUTION: SEE BELOW</td>\n",
              "      <td>4.011320e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C00697441</td>\n",
              "      <td>A</td>\n",
              "      <td>Q2</td>\n",
              "      <td>P2020</td>\n",
              "      <td>202001089167037290</td>\n",
              "      <td>15E</td>\n",
              "      <td>IND</td>\n",
              "      <td>FREEMON, PHILLIP</td>\n",
              "      <td>SAN FRANCISCO</td>\n",
              "      <td>CA</td>\n",
              "      <td>...</td>\n",
              "      <td>SELF-EMPLOYED</td>\n",
              "      <td>ATTORNEY</td>\n",
              "      <td>5292019.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>C00401224</td>\n",
              "      <td>867438</td>\n",
              "      <td>1369136.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>* EARMARKED CONTRIBUTION: SEE BELOW</td>\n",
              "      <td>4.011320e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C00697441</td>\n",
              "      <td>A</td>\n",
              "      <td>Q2</td>\n",
              "      <td>P2020</td>\n",
              "      <td>202001089167043820</td>\n",
              "      <td>15E</td>\n",
              "      <td>IND</td>\n",
              "      <td>LOCKHART, ARTHUR</td>\n",
              "      <td>SAN RAMON</td>\n",
              "      <td>CA</td>\n",
              "      <td>...</td>\n",
              "      <td>MVI HEALTH INC</td>\n",
              "      <td>EXECUTIVE</td>\n",
              "      <td>4202019.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>C00401224</td>\n",
              "      <td>769500</td>\n",
              "      <td>1369136.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>* EARMARKED CONTRIBUTION: SEE BELOW</td>\n",
              "      <td>4.011320e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C00697441</td>\n",
              "      <td>A</td>\n",
              "      <td>Q2</td>\n",
              "      <td>P2020</td>\n",
              "      <td>202001089167043821</td>\n",
              "      <td>15E</td>\n",
              "      <td>IND</td>\n",
              "      <td>LOCKHART, ARTHUR</td>\n",
              "      <td>SAN RAMON</td>\n",
              "      <td>CA</td>\n",
              "      <td>...</td>\n",
              "      <td>MVI HEALTH INC</td>\n",
              "      <td>EXECUTIVE</td>\n",
              "      <td>5202019.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>C00401224</td>\n",
              "      <td>846695</td>\n",
              "      <td>1369136.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>* EARMARKED CONTRIBUTION: SEE BELOW</td>\n",
              "      <td>4.011320e+18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     CMTE_ID AMNDT_IND RPT_TP TRANSACTION_PGI           IMAGE_NUM  \\\n",
              "0     GINEER  05232019    250       C00401224              857500   \n",
              "1  C00697441         A     Q2           P2020  202001089167037289   \n",
              "2  C00697441         A     Q2           P2020  202001089167037290   \n",
              "3  C00697441         A     Q2           P2020  202001089167043820   \n",
              "4  C00697441         A     Q2           P2020  202001089167043821   \n",
              "\n",
              "  TRANSACTION_TP ENTITY_TP                                 NAME  \\\n",
              "0        1369136       NaN  * EARMARKED CONTRIBUTION: SEE BELOW   \n",
              "1            15E       IND                     FREEMON, PHILLIP   \n",
              "2            15E       IND                     FREEMON, PHILLIP   \n",
              "3            15E       IND                     LOCKHART, ARTHUR   \n",
              "4            15E       IND                     LOCKHART, ARTHUR   \n",
              "\n",
              "                  CITY STATE  ...        EMPLOYER OCCUPATION TRANSACTION_DT  \\\n",
              "0  4011320201684008049  None  ...            None       None            NaN   \n",
              "1        SAN FRANCISCO    CA  ...   SELF-EMPLOYED   ATTORNEY      4162019.0   \n",
              "2        SAN FRANCISCO    CA  ...   SELF-EMPLOYED   ATTORNEY      5292019.0   \n",
              "3            SAN RAMON    CA  ...  MVI HEALTH INC  EXECUTIVE      4202019.0   \n",
              "4            SAN RAMON    CA  ...  MVI HEALTH INC  EXECUTIVE      5202019.0   \n",
              "\n",
              "   TRANSACTION_AMT   OTHER_ID TRAN_ID   FILE_NUM  MEMO_CD  \\\n",
              "0              NaN       None    None        NaN     None   \n",
              "1           1000.0  C00401224  747383  1369136.0      NaN   \n",
              "2           1000.0  C00401224  867438  1369136.0      NaN   \n",
              "3            250.0  C00401224  769500  1369136.0      NaN   \n",
              "4            250.0  C00401224  846695  1369136.0      NaN   \n",
              "\n",
              "                             MEMO_TEXT        SUB_ID  \n",
              "0                                 None           NaN  \n",
              "1  * EARMARKED CONTRIBUTION: SEE BELOW  4.011320e+18  \n",
              "2  * EARMARKED CONTRIBUTION: SEE BELOW  4.011320e+18  \n",
              "3  * EARMARKED CONTRIBUTION: SEE BELOW  4.011320e+18  \n",
              "4  * EARMARKED CONTRIBUTION: SEE BELOW  4.011320e+18  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.shape[0]\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08cbcbda",
      "metadata": {
        "id": "08cbcbda"
      },
      "source": [
        "## Filter out irrelevant contribution data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bd84270",
      "metadata": {
        "id": "9bd84270"
      },
      "outputs": [],
      "source": [
        "can_ids = pd.read_excel('filtered_project_committees.xlsx')\n",
        "can_ids_list = can_ids['committee_id'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1700aae8",
      "metadata": {
        "id": "1700aae8",
        "outputId": "9acc3e7e-3ecc-4058-8fee-1a71418735ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(can_ids_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0cc75f",
      "metadata": {
        "id": "cf0cc75f",
        "outputId": "39ad8991-d0a4-4dee-8616-c146ed6eab53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "402720"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_df1 = df1[df1['CMTE_ID'].isin(can_ids_list)]\n",
        "#filtered_df1.to_csv('test2_year_16.csv', index=False)\n",
        "filtered_df1.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528ffcc6",
      "metadata": {
        "id": "528ffcc6"
      },
      "source": [
        "## Drop irrelevant columns and format date columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9161bd6b",
      "metadata": {
        "id": "9161bd6b",
        "outputId": "26d30dec-e49f-41c1-d7de-4c1fb88eb834"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_14680\\3990120306.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected_columns['TRANSACTION_DT'] = selected_columns['TRANSACTION_DT'].astype(str)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "402720"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_columns = filtered_df1[['CMTE_ID', 'TRANSACTION_DT', 'TRANSACTION_AMT']]\n",
        "selected_columns['TRANSACTION_DT'] = selected_columns['TRANSACTION_DT'].astype(str)\n",
        "selected_columns.to_csv('poop.csv', index=False)\n",
        "selected_columns.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04fb08ef",
      "metadata": {
        "id": "04fb08ef",
        "outputId": "5deb803c-14be-44f4-f1f1-a94e1bee184c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "402720"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove rows with out properly formated dates\n",
        "selected_columns = selected_columns[selected_columns['TRANSACTION_DT'].apply(len).isin([9, 10])]\n",
        "selected_columns.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2815b010",
      "metadata": {
        "id": "2815b010"
      },
      "outputs": [],
      "source": [
        "# formate date column\n",
        "selected_columns['Year'] = selected_columns['TRANSACTION_DT'].str[-6:-2]\n",
        "selected_columns['Date'] = selected_columns['TRANSACTION_DT'].str[-8:-6]\n",
        "selected_columns['Month'] = selected_columns['TRANSACTION_DT'].str[:-8]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a536b8",
      "metadata": {
        "id": "57a536b8",
        "outputId": "a0fcf347-2671-4221-da53-686c27853d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "402223"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove rows that arnt within two years of the election\n",
        "selected_columns = selected_columns[selected_columns['Year'].str.startswith((yeara, yearb))]\n",
        "selected_columns.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe5c3a9",
      "metadata": {
        "id": "3fe5c3a9"
      },
      "source": [
        "## Verify Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15f262f",
      "metadata": {
        "id": "a15f262f",
        "outputId": "6c886ed7-88c4-42ae-adda-efc4e8162aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Month  Year   Count\n",
            "0      1  2019   12588\n",
            "2      2  2019   13663\n",
            "3      3  2019   17221\n",
            "4      4  2019   16285\n",
            "6      5  2019   19484\n",
            "8      6  2019    2693\n",
            "5      4  2020   93943\n",
            "7      5  2020   69535\n",
            "1     11  2020  156811\n"
          ]
        }
      ],
      "source": [
        "unique_combos = selected_columns[['Month', 'Year']]\n",
        "\n",
        "# Group by 'Month' and 'Year', then get the counts\n",
        "combo_counts = unique_combos.groupby(['Month', 'Year']).size().reset_index(name='Count')\n",
        "combo_counts = combo_counts.apply(pd.to_numeric)\n",
        "combo_counts = combo_counts.sort_values(by=['Year', 'Month'])\n",
        "print(combo_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9148a490",
      "metadata": {
        "id": "9148a490"
      },
      "outputs": [],
      "source": [
        "# Convert 'Count' column to list\n",
        "count_list = combo_counts['Count'].tolist()\n",
        "\n",
        "# Check if any value is less than 100\n",
        "if any(count < 50 for count in count_list):\n",
        "    print('WELP')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee83ea7",
      "metadata": {
        "id": "3ee83ea7"
      },
      "source": [
        "## A for loop for the 14 small file (same code as above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21d662db",
      "metadata": {
        "id": "21d662db"
      },
      "outputs": [],
      "source": [
        "# create 'months' folder if it doesn't exist\n",
        "if not os.path.exists('2020_files'):\n",
        "    os.makedirs('2020_files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f785097",
      "metadata": {
        "id": "3f785097"
      },
      "outputs": [],
      "source": [
        "selected_columns.to_csv(f'2020_files/df{number}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a9a8f8",
      "metadata": {
        "id": "f3a9a8f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc42d9c",
      "metadata": {
        "id": "bcc42d9c"
      },
      "outputs": [],
      "source": [
        "# Create a list of numbers from 001 to 014\n",
        "number_list = [str(i).zfill(3) for i in range(4, 5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c00e71",
      "metadata": {
        "id": "67c00e71",
        "outputId": "3027e352-f482-4906-d9cd-a7c5ed543238"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['004']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b598624",
      "metadata": {
        "id": "2b598624",
        "outputId": "47d28533-1c70-4af1-9a56-ee2303eb1cfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_14680\\4014223319.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df1 = pd.read_csv(f'chunks/20.txt.{n}.txt', sep='|', engine='python', names=column_names, error_bad_lines=False)\n",
            "Skipping line 544571: '|' expected after '\"'\n",
            "Skipping line 781538: '|' expected after '\"'\n",
            "Skipping line 1448751: '|' expected after '\"'\n",
            "Skipping line 2557942: '|' expected after '\"'\n",
            "Skipping line 5079060: '|' expected after '\"'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Month, Year, Count]\n",
            "Index: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joel\\AppData\\Local\\Temp\\ipykernel_14680\\4014223319.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  selected_columns['TRANSACTION_DT'] = selected_columns['TRANSACTION_DT'].astype(str)\n"
          ]
        }
      ],
      "source": [
        "for n in number_list:\n",
        "    #df1 = pd.read_csv('20.txt', sep='|', names=column_names)\n",
        "    df1 = pd.read_csv(f'chunks/20.txt.{n}.txt', sep='|', engine='python', names=column_names, error_bad_lines=False)\n",
        "\n",
        "\n",
        "    df1.shape[0]\n",
        "    df1.head()\n",
        "\n",
        "    ## Filter out irrelevant contribution data\n",
        "\n",
        "    can_ids = pd.read_excel('filtered_project_committees.xlsx')\n",
        "    can_ids_list = can_ids['committee_id'].to_list()\n",
        "\n",
        "    len(can_ids_list)\n",
        "\n",
        "    filtered_df1 = df1[df1['CMTE_ID'].isin(can_ids_list)]\n",
        "    #filtered_df1.to_csv('test2_year_16.csv', index=False)\n",
        "    filtered_df1.shape[0]\n",
        "\n",
        "    ## Drop irrelevant columns and format date columns\n",
        "\n",
        "    selected_columns = filtered_df1[['CMTE_ID', 'TRANSACTION_DT', 'TRANSACTION_AMT']]\n",
        "    selected_columns['TRANSACTION_DT'] = selected_columns['TRANSACTION_DT'].astype(str)\n",
        "\n",
        "    # remove rows with out properly formated dates\n",
        "    selected_columns = selected_columns[selected_columns['TRANSACTION_DT'].apply(len).isin([9, 10])]\n",
        "\n",
        "    # formate date column\n",
        "    selected_columns['Year'] = selected_columns['TRANSACTION_DT'].str[-6:-2]\n",
        "    selected_columns['Date'] = selected_columns['TRANSACTION_DT'].str[-8:-6]\n",
        "    selected_columns['Month'] = selected_columns['TRANSACTION_DT'].str[:-8]\n",
        "\n",
        "    # remove rows that arnt within two years of the election\n",
        "    selected_columns = selected_columns[selected_columns['Year'].str.startswith((yeara, yearb))]\n",
        "    selected_columns.shape[0]\n",
        "\n",
        "    ## Verify Data Quality\n",
        "\n",
        "    unique_combos = selected_columns[['Month', 'Year']]\n",
        "\n",
        "    # Group by 'Month' and 'Year', then get the counts\n",
        "    combo_counts = unique_combos.groupby(['Month', 'Year']).size().reset_index(name='Count')\n",
        "    combo_counts = combo_counts.apply(pd.to_numeric)\n",
        "    combo_counts = combo_counts.sort_values(by=['Year', 'Month'])\n",
        "    print(combo_counts)\n",
        "\n",
        "    # Convert 'Count' column to list\n",
        "    count_list = combo_counts['Count'].tolist()\n",
        "\n",
        "    # Check if any value is less than 100\n",
        "    if any(count < 50 for count in count_list):\n",
        "        print('WELP')\n",
        "        break\n",
        "\n",
        "\n",
        "    ## Create and download an excel file for each month of contributions\n",
        "\n",
        "    # create 'months' folder if it doesn't exist\n",
        "    if not os.path.exists('2020_files'):\n",
        "        os.makedirs('2020_files')\n",
        "\n",
        "    selected_columns.to_csv(f'2020_files/df{n}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a06926",
      "metadata": {
        "id": "92a06926"
      },
      "source": [
        "## Create and download an excel file for each month of contributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce2c1ab",
      "metadata": {
        "id": "bce2c1ab"
      },
      "outputs": [],
      "source": [
        "folder_path = '2020_files/'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through each file in the folder\n",
        "for i in range(1, 15):\n",
        "    # Generate the file name\n",
        "    filename = f'df{i:03d}.csv'\n",
        "    filepath = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Append the DataFrame to the list\n",
        "    dfs.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77475ef2",
      "metadata": {
        "id": "77475ef2",
        "outputId": "296687c9-b4df-45df-b8f0-cecba3d1f9df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5114995"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_14 = pd.concat(dfs, ignore_index=True)\n",
        "all_14.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2a2e51",
      "metadata": {
        "id": "8d2a2e51"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06f9858",
      "metadata": {
        "id": "b06f9858"
      },
      "outputs": [],
      "source": [
        "#create a df with all 14 named all_14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de081d3c",
      "metadata": {
        "id": "de081d3c"
      },
      "outputs": [],
      "source": [
        "# create 'months' folder if it doesn't exist\n",
        "if not os.path.exists('months'):\n",
        "    os.makedirs('months')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4037e1ce",
      "metadata": {
        "id": "4037e1ce",
        "outputId": "07194305-3d70-4ab8-babc-20e1dd6034d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 2020\n",
            "10 2020\n",
            "6 2020\n",
            "8 2020\n",
            "11 2019\n",
            "11 2020\n",
            "10 2019\n",
            "3 2020\n",
            "4 2020\n",
            "12 2020\n",
            "1 2020\n",
            "12 2019\n",
            "7 2019\n",
            "6 2019\n",
            "4 2019\n",
            "5 2019\n",
            "2 2019\n",
            "1 2019\n",
            "3 2019\n",
            "5 2020\n",
            "9 2019\n",
            "8 2019\n",
            "7 2020\n",
            "2 2020\n",
            "Data frames have been saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# list of all months\n",
        "unique_year_month_combos = all_14[['Year', 'Month']].drop_duplicates()\n",
        "year_month_list = [(row['Year'], row['Month']) for _, row in unique_year_month_combos.iterrows()]\n",
        "\n",
        "# iterate over each month\n",
        "for year, month in year_month_list:\n",
        "    print(month, year)\n",
        "    filtered_df = all_14[(all_14['Year'] == year) & (all_14['Month'] == month)]\n",
        "\n",
        "    # save to the folder\n",
        "    file_path = os.path.join('months/', f'{year}_{month}.csv')\n",
        "    filtered_df.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"Data frames have been saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f77acfa",
      "metadata": {
        "id": "3f77acfa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}